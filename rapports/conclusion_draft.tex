\chapter*{Conclusion}           % ne pas numéroter
\label{chap:conclusion}         % étiquette pour renvois
\phantomsection\addcontentsline{toc}{chapter}{\nameref{chap:conclusion}} % inclure dans TdM

La détection d'anomalies est une tâche qui comporte généralement plusieurs défis en modélisation et en analyse de données. Ces défis, dont entres autres l'absence d'étiquettes pour l'entraînement, ont été mentionnés et décrits brièvement dans le chapitre d'\nameref{chap:introduction}. Notre objectif est de proposer une méthodologie qui permet d'identifier les images d'un jeu de données qui dévient de la normalité et qui s'apparentent donc à des anomalies. Nous souhaitons faire cette détection d'anomalies de manière non supervisée tout en simplifiant l'établissement du seuil nous permettant de catégoriser une observation "normale" et une observation "anormale". 

Dans ce mémoire, nous démontrons la pertinence d'utiliser des autoencodeurs variationnels pour faire face à aux défis traditionnels reliés à la détection d'anomalies, tout en restant efficaces dans un contexte où les données sont complexes, comme des images. Nous discutons également de différentes approches permettant de faire la détection d'anomalies, en mettant l'accent sur les méthodes d'autoencodeurs qui sont bien adaptées pour traiter des images.

Dans les expérimentations réalisées et présentées dans le chapitre \ref{chap:experiments}, nous sommes en mesure de conclure que notre approche produit des résultats performants autant sur des jeux de données d'images réelles que d'images simples. La valeur ajoutée de notre approche par rapport à d'autres méthodes est toutefois beaucoup plus évidente dans le cas d'images réelles. En effet, les performances obtenues par notre approche sur des images simples, comme \textit{MNIST}, ne sont généralement pas significativement meilleures ou pires que d'autres approches. En revanche, les performances en aire sous la courbe ROC, en précision et en rappel obtenues sur des images réelles plus complexes, comme \textit{ImageNet}, sont supérieures aux autres approches comparatives. Ces bonnes performances nous laissent croire que nous avons rempli notre objectif d'être en mesure de détecter des anomalies dans un ensemble d'images. De plus, la mise en place de notre niveau de filtration $\alpha$ nous permet d'avoir un seuil simple et intuitif à établir.


 Le facteur principal expliquant les bonnes performances obtenues sur des images réelles est l'utilisation d'un autoencodeur variationnel. En effet, cet algorithme d'apprentissage profond permet de représenter des données complexes dans une forme latente beaucoup plus simple et qui permet aussi de bien discriminer des observations "normales" et des observations "anormales". Un des avantages de notre approche est que les performances en détection d'anomalies demeurent élevées dans plusieurs scénarios différents: différentes complexités d'images, différentes proportions de contamination, etc. Un des points faibles de notre approche est que l'autoencodeur variationnel est un algorithme relativement complexe, qui demande beaucoup de configurations. En effet, il faut déterminer plusieurs hyperparamètres comme le nombre de couches de l'autoencodeur, la taille des filtres, les fonctions d'activation, la taille de la dimension latente, etc. C'est d'ailleurs un point commun à la majorité des approches basées sur les réseaux de neurones. Ensuite, un autre point faible de notre approche est qu'on doit réaliser une étape manuelle, après l'entraînement de l'autoencodeur, où on doit inspecter certaines observations. Cette étape fait en sorte que notre méthodologie n'est pas pleinement automatique.
 
À la lumière de nos résultats, notre approche pourrait être utilisée pour plusieurs applications ou situations réelles où l'on cherche à identifier des images "anormales". Prenons par exemple une situation où l'on bénéficie d'un ensemble d'images propres pour lequel on sait qu'il n'y a pas d'anomalies ou de défectuosités. Supposons que dans le futur, on prévoit recevoir de nouvelles images qui sont supposées représenter la même chose que notre ensemble d'images propres, mais dont certaines de ces nouvelles images sont défectueuses où représentent quelque chose de complètement différent. Nous ne connaissons pas d'avance à quoi ces images défectueuses pourraient ressembler et n'avons aucun exemple d'image de la sorte sur lesquelles on pourrait faire un apprentissage. Notre approche permettrait donc de déterminer lesquelles de ces nouvelles images sont potentiellement défectueuses ou ne semblent pas représenter la même chose que notre ensemble d'images a priori. On pourrait également penser à des exemples d'applications où l'on cherche à nettoyer un jeu de données d'images. En effet, on pourrait commencer par valider et confirmer un sous-ensemble d'images propres dans notre jeu de données complet. Ensuite, on pourrait utiliser ce sous-ensemble comme jeu de données d'entraînement pour notre approche. Finalement, on pourrait utiliser le reste du jeu de données comme jeu de données de test et ainsi valider si des images "anormales" font parties de notre ensemble global. Cela reviendrait donc à utiliser notre approche comme technique de nettoyage de données.

Dans le futur, il serait intéressant de voir si des variations de l'autoencodeur variationnel pourraient donner de meilleurs résultats en détection d'anomalies. Parmi les possibilités de variations, il serait intéressant de voir si une autre loi que la $N(0,I)$ pourrait être utilisée comme loi a priori de la représentation latente et définir une statistique de distance sur cette nouvelle représentation latente. L'objectif serait d'explorer d'autres lois qui pourraient mieux discriminer des observations "normales" d'un petit groupe d'observations "anormales". Ensuite, il serait pertinent de voir s'il est possible de mieux contrôler les 2 composantes de pertes de l'autoencodeur variationnel. De ce fait, nous avons remarqué que ces deux composantes ont parfois des échelles très différentes, ce qui affecte l'entraînement de l'autoencodeur et la composition de la représentation latente. Dans ce mémoire, nous avons fait plusieurs essaies et avons utilisé l'hyperparamètre $\beta$  pour modifier la pondération des deux composantes de perte. Cette approche requiert donc beaucoup d'essaies et erreurs, ce qui n'est pas optimal. Finalement, il serait également intéressant de voir s'il est possible de faire en sorte que les représentations latentes des anomalies se comportent toujours de la même manière par rapport à un point de référence, soit la distribution $N(0,I)$ dans notre cas. En effet, nous avons remarqué que selon la nature des données, les représentations latentes des anomalies se retrouvaient dans certains cas plus près de la $N(0,I)$ et dans certains cas  plus éloignées de la $N(0,I)$. Ce constat ajoute une étape manuelle pour mettre en place notre méthodologie, ce qui rend l'approche moins automatique et plus difficile à appliquer dans la pratique. Au final, nous pouvons conclure que l'autoencodeur variationnel possède des propriétés intéressantes, via l'apprentissage d'une représentation latente, pour faire de la détection d'anomalies sur des données complexes comme des images.


