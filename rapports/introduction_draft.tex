\chapter*{Introduction}         % ne pas numéroter
\label{chap:introduction}       % étiquette pour renvois
\phantomsection\addcontentsline{toc}{chapter}{\nameref{chap:introduction}} % inclure dans TdM


La détection d'anomalies est un sujet complexe qui a généré beaucoup de littérature en statistique,  en apprentissage machine et plus récemment en vision numérique. Il existe plusieurs applications de ces méthodes dans les domaines de la cyber-intrusion, de la finance et de l'assurance, de la médecine ou dans l'identification de dommages industriels \citep{chandola2009anomaly}. Une anomalie est définie par \cite{Zimek2017} comme un événement, une mesure ou une observation qui diffère significativement de la majorité des données. Une anomalie, également appelée une aberration, est une notion intrinsèque à plusieurs domaines reliés à l'analyse des données, car une donnée anormales ou aberrante est généralement intéressante à identifier ou retirer d'une source de données. Dans un premier temps, il peut être intéressant de l'identifier simplement parce que c'est  l'objectif poursuivi en soi. Dans un deuxième temps, il peut également être pertinent de retirer une observation anormale ou aberrante avant de réaliser une autre tâche d'apprentissage. 

Une difficulté reliée à la détection d'anomalies est qu'on doit souvent utiliser des données non étiquetées, car les anomalies sont généralement générées par des phénomènes imprévus. Cela fait en sorte qu'on doit approcher le problème de manière non-supervisée. Une autre difficulté, plus particulièrement reliée avec les approches non-supervisées, est qu'il faut généralement déterminer un seuil nous permettant de prendre une décision quant à la nature d'une donnée (anomalie ou non). Finalement, ces difficultés deviennent encore plus prononcées lorsqu'on doit traiter des données complexes, comme des images.

Dans le contexte de données à hautes dimensions, les réseaux de neurones sont couramment utilisés. En effet, leurs couches superposées peuvent partir d'une entrée complexe, comme une image, et compresser cette information vers une représentation vectorielle plus compacte et riche en informations. Les autoencodeurs sont une catégorie de réseaux de neurones fréquemment utilisés en apprentissage non-supervisé. Il existe d'ailleurs plusieurs applications d'autoencodeurs dans un contexte de détection d'anomalies, où l'erreur de reconstruction est souvent utilisée comme indicateur d'anomalie. Cependant, ces méthodes requièrent de fixer un seuil de détection, souvent sous forme de distance ou de métrique, qui peut être difficile à établir ou à expliquer. C'est d'ailleurs pour cette raison que  \cite{An2015VariationalAB} proposent de se baser sur une probabilité de reconstruction, qui est une mesure objective et ne requiert pas de seuil quelconque. Par contre, cette mesure de probabilité est basée sur la capacité de reconstruction des observations originales, ce qui peut être problématique dans le contexte d'images complexes, plutôt que sur la représentation latente, qui elle peut être beaucoup plus simple. D'autres approches, comme dans \cite{DBLP:journals/corr/abs-1802-06360} se basent plutôt sur cette représentation latente pour faire la détection d'anomalies. C'est davantage vers ce type d'approches que nous souhaitons orienter notre méthodologie. 

Dans ce mémoire, nous proposons une approche qui vise à faire la détection d'anomalies dans un ensemble de données constitué d'images. Nous proposons également de simplifier la détermination du seuil nécessaire pour conclure quelles observations sont "normales" et quelles observations sont "anormales". Avec cette contribution, nous proposons d'utiliser des méthodes existantes comme des autoencodeurs  pour encoder des structures de données complexes dans des représentations latentes qui serviront de base pour un cadre décisionnel simple et intuitif à appliquer. À partir d'autoencodeurs variationnels (VAE), nous sommes en mesure de créer ces dites représentations et de détecter les anomalies dans un ensemble d'images.
