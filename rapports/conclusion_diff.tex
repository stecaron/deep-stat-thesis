\chapter*{Conclusion}           % ne pas numéroter
\label{chap:conclusion}         % étiquette pour renvois
\phantomsection\addcontentsline{toc}{chapter}{\nameref{chap:conclusion}} % inclure dans TdM

La détection d'anomalies est une tâche qui comporte généralement plusieurs défis en modélisation et en analyse de données. Ces défis, dont entres autres l'absence d'étiquettes pour l'entraînement, ont été mentionnés et décrits brièvement dans le chapitre \DIFaddbegin \DIFadd{d'}\DIFaddend \nameref{chap:introduction}. Dans ce mémoire, nous démontrons la pertinence d'utiliser des autoencodeurs variationnels pour \DIFdelbegin \DIFdel{adresser }\DIFdelend \DIFaddbegin \DIFadd{faire face à }\DIFaddend ces défis \DIFdelbegin \DIFdel{traditionnelles }\DIFdelend \DIFaddbegin \DIFadd{traditionnels }\DIFaddend reliés à la détection d'anomalies\DIFaddbegin \DIFadd{, }\DIFaddend tout en restant \DIFdelbegin \DIFdel{efficace dans une }\DIFdelend \DIFaddbegin \DIFadd{efficaces dans un }\DIFaddend contexte où les données sont complexes, comme des images. En bout de ligne, notre approche nous aide à identifier les images d'un jeu de données qui dévient de la normalité et qui s'apparentent donc à des anomalies. La méthodologie que nous proposons pour arriver à faire cette discrimination se base d'ailleurs sur un niveau de filtration, ou d'acceptabilité, intuitif et simple à établir.

Dans les expérimentations réalisées et présentées dans le chapitre \ref{chap:experiments}, nous sommes en mesure de conclure que notre approche produit des résultats performants autant sur des jeux de données d'images réelles que d'images simples. La valeur ajoutée de notre approche par rapport à d'autres méthodes est toutefois beaucoup plus évidente dans le cas d'images réelles. En effet, les performances obtenues par notre approche sur des images simples, comme \textit{MNIST}, ne sont généralement pas significativement meilleures ou pires que d'autres approches. En revanche, les performances en aire sous la courbe ROC, en précision et en rappel obtenues sur des images réelles plus complexes, comme \textit{ImageNet}, sont supérieures aux autres approches comparatives. Nous avons remarqué que l'autoencodeur variationnel permet de représenter les données complexes dans une forme latente beaucoup plus simple et qui permet aussi de bien discriminer les anomalies des observations "normales". 

À la lumière de ces résultats, notre approche pourrait être utilisée pour plusieurs applications ou situations réelles où l'on cherche à identifier des images "anormales". Prenons par exemple une situation où l'on bénéficie d'un ensemble d'images propres pour lequel on sait qu'il n'y a pas d'anomalies ou de défectuosités. Supposons que dans le futur, on prévoit recevoir de nouvelles images qui sont supposées représenter la même chose que notre ensemble d'images propres, mais dont certaines de ces nouvelles images sont défectueuses où représentent quelque chose de complètement différent. Nous ne connaissons pas d'avance à quoi ces images défectueuses pourraient ressembler et n'avons aucun exemple d'image de la sorte sur lesquelles on pourrait faire un apprentissage. Notre approche permettrait donc de déterminer lesquelles de ces nouvelles images sont potentiellement défectueuses ou ne semblent pas représenter la même chose que notre ensemble d'images a priori. On pourrait également penser à des exemples d'applications où l'on cherche à nettoyer un jeu de données d'images. En effet, on pourrait commencer par valider et confirmer un sous-ensemble d'images propres dans notre jeu de données complet. Ensuite, on pourrait utiliser ce sous-ensemble comme jeu de données d'entraînement pour notre approche. Finalement, on pourrait utiliser le reste du jeu de données comme jeu de données de test et ainsi valider si des images "anormales" font parties de notre ensemble global. Cela reviendrait donc \DIFaddbegin \DIFadd{à }\DIFaddend utiliser notre approche comme technique de nettoyage de données.

Dans le futur, il serait intéressant de voir si des variations de l'autoencodeur variationnel pourraient donner des résultats encore plus performants en détection d'anomalies. Parmi les possibilités de variations, il serait intéressant de voir si une autre loi que la $N(0,I)$ pourrait être utilisée comme loi a priori de la représentation latente et définir une statistique de distance sur cette nouvelle représentation latente qui discriminerait encore mieux les anomalies des observations "normales". Ensuite, il serait également intéressant de voir s'il est possible de faire en sorte que les représentations latentes des anomalies se comportent toujours de la même manière par rapport à un point de référence, soit la distribution $N(0,I)$ dans notre cas. En effet, nous avons remarqué que selon la nature des données, les représentations latentes des anomalies se retrouvaient dans certains cas plus près de la $N(0,I)$ et dans certains cas  plus éloignées de la $N(0,I)$. Ce constat ajoute une étape manuelle pour mettre en place notre méthodologie, ce qui rend l'approche moins \DIFdelbegin \DIFdel{autonome }\DIFdelend \DIFaddbegin \DIFadd{automatique }\DIFaddend et plus difficile à appliquer dans la pratique. Au final, nous pouvons conclure que l'autoencodeur variationnel possède des propriétés intéressantes, via l'apprentissage d'une représentation latente, pour faire de la détection d'anomalies sur des données complexes comme des images.


